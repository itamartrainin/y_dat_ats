{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro"
    ]
   },
   "source": [
    "# Grading process\n",
    "\n",
    "\n",
    "The submission notebook will be autovalidated with `papermill`. The exact command is the following:\n",
    "\n",
    "```bash\n",
    "papermill <notebook-name>.ipynb <notebook-name>-run.ipynb .ipynb -p TEST True\n",
    "```\n",
    "\n",
    "Papermill will inject new cell after each cell tagged as `parameters` (see `View > Cell toolbar > Tags`). Notebook will be executed from top to bottom in a linear order. `solutions.py` contains correct implementations used to validate your solutions.\n",
    "\n",
    "Please, **fill `STUDENT` variable with the name of submitting student**, so that we can collect the results automatically. Please, **do not change `TEST` variable** and `validation` cells. If you need to inject your own code for testing, wrap it into\n",
    "\n",
    "```python\n",
    "if not TEST:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Different problems give different number of points. All problems in the basic section give 1 point, while all problems in intermediate section give 2 points.\n",
    "\n",
    "Each problem contains specific validation details. You need to fill each cell tagged `solution` with your code. Note, that solution function must self-contained, i.e. it must not use any state from the notebook itself.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "All problems in the assignment use [electricity load dataset](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014). Some functions/methods accept data itself, and in that case it's a Pandas dataframe as obtained by\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "In contrast, whenever a function/method accepts a filename, it's the filename of **unzipped** data file (i.e. `LD2011_2014.txt`). When testing, do not rely on any specific location of the dataset, as validation environment will most certainly different from your local one. Hence, calls like\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"<your-local-directory>/LD2011_2014.txt\")\n",
    "```\n",
    "\n",
    "will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.111972Z",
     "start_time": "2019-10-30T22:26:04.107385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.372936Z",
     "start_time": "2019-10-30T22:26:04.364608Z"
    }
   },
   "outputs": [],
   "source": [
    "STUDENT = \"Itamar Trainin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ASSIGNMENT = 1\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:38.188583Z",
     "start_time": "2019-10-30T22:39:38.182534Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    import solutions\n",
    "    total_grade = 0\n",
    "    MAX_POINTS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp    MT_001     MT_002    MT_003      MT_004  \\\n",
      "0      2011-01-01 00:15:00  0.000000   0.000000  0.000000    0.000000   \n",
      "1      2011-01-01 00:30:00  0.000000   0.000000  0.000000    0.000000   \n",
      "2      2011-01-01 00:45:00  0.000000   0.000000  0.000000    0.000000   \n",
      "3      2011-01-01 01:00:00  0.000000   0.000000  0.000000    0.000000   \n",
      "4      2011-01-01 01:15:00  0.000000   0.000000  0.000000    0.000000   \n",
      "...                    ...       ...        ...       ...         ...   \n",
      "140251 2014-12-31 23:00:00  2.538071  22.048364  1.737619  150.406504   \n",
      "140252 2014-12-31 23:15:00  2.538071  21.337127  1.737619  166.666667   \n",
      "140253 2014-12-31 23:30:00  2.538071  20.625889  1.737619  162.601626   \n",
      "140254 2014-12-31 23:45:00  1.269036  21.337127  1.737619  166.666667   \n",
      "140255 2015-01-01 00:00:00  2.538071  19.914651  1.737619  178.861789   \n",
      "\n",
      "           MT_005      MT_006     MT_007      MT_008     MT_009  ...  \\\n",
      "0        0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "1        0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "2        0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "3        0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "4        0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "...           ...         ...        ...         ...        ...  ...   \n",
      "140251  85.365854  303.571429  11.305822  282.828283  68.181818  ...   \n",
      "140252  81.707317  324.404762  11.305822  252.525253  64.685315  ...   \n",
      "140253  82.926829  318.452381  10.175240  242.424242  61.188811  ...   \n",
      "140254  85.365854  285.714286  10.175240  225.589226  64.685315  ...   \n",
      "140255  84.146341  279.761905  10.175240  249.158249  62.937063  ...   \n",
      "\n",
      "            MT_361   MT_362       MT_363       MT_364     MT_365    MT_366  \\\n",
      "0         0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "1         0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "2         0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "3         0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "4         0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "...            ...      ...          ...          ...        ...       ...   \n",
      "140251  276.945039  28200.0  1616.033755  1363.636364  29.986962  5.851375   \n",
      "140252  279.800143  28300.0  1569.620253  1340.909091  29.986962  9.947338   \n",
      "140253  284.796574  27800.0  1556.962025  1318.181818  27.379400  9.362200   \n",
      "140254  246.252677  28000.0  1443.037975   909.090909  26.075619  4.095963   \n",
      "140255  188.436831  27800.0  1409.282700   954.545455  27.379400  4.095963   \n",
      "\n",
      "            MT_367      MT_368      MT_369       MT_370  \n",
      "0         0.000000    0.000000    0.000000     0.000000  \n",
      "1         0.000000    0.000000    0.000000     0.000000  \n",
      "2         0.000000    0.000000    0.000000     0.000000  \n",
      "3         0.000000    0.000000    0.000000     0.000000  \n",
      "4         0.000000    0.000000    0.000000     0.000000  \n",
      "...            ...         ...         ...          ...  \n",
      "140251  697.102722  176.961603  651.026393  7621.621622  \n",
      "140252  671.641791  168.614357  669.354839  6702.702703  \n",
      "140253  670.763828  153.589316  670.087977  6864.864865  \n",
      "140254  664.618086  146.911519  646.627566  6540.540541  \n",
      "140255  628.621598  131.886477  673.020528  7135.135135  \n",
      "\n",
      "[140256 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    df = pd.read_csv(\"C:\\Data\\Electricity Load Dataset\\LD2011_2014.txt\",\n",
    "                 parse_dates=[0], \n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "    df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 1. Resample the dataset (1 point)\n",
    "\n",
    "Resample the dataset to 1-hour resolution. Use `mean` as an aggregation function. Your function must output a dataframe, with the same structure as the original one (i.e. not indexed by datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.100307Z",
     "start_time": "2019-10-30T22:26:07.092132Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def el_resample(df):\n",
    "    return df.groupby(pd.Grouper(key='timestamp', freq='1H')).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.334174Z",
     "start_time": "2019-10-30T22:26:07.322103Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Itamar Trainin\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT_001       2.220812\n",
      "MT_002      21.337127\n",
      "MT_003       1.737619\n",
      "MT_004     161.585366\n",
      "MT_005      83.841463\n",
      "             ...     \n",
      "MT_366       7.314219\n",
      "MT_367     676.031607\n",
      "MT_368     161.519199\n",
      "MT_369     659.274194\n",
      "MT_370    6932.432432\n",
      "Length: 370, dtype: float64\n",
      "                timestamp    MT_001     MT_002    MT_003      MT_004  \\\n",
      "0     2011-01-01 00:00:00  0.000000   0.000000  0.000000    0.000000   \n",
      "1     2011-01-01 01:00:00  0.000000   0.000000  0.000000    0.000000   \n",
      "2     2011-01-01 02:00:00  0.000000   0.000000  0.000000    0.000000   \n",
      "3     2011-01-01 03:00:00  0.000000   0.000000  0.000000    0.000000   \n",
      "4     2011-01-01 04:00:00  0.000000   0.000000  0.000000    0.000000   \n",
      "...                   ...       ...        ...       ...         ...   \n",
      "35060 2014-12-31 20:00:00  2.220812  25.248933  1.737619  186.483740   \n",
      "35061 2014-12-31 21:00:00  2.538071  22.759602  1.737619  162.093496   \n",
      "35062 2014-12-31 22:00:00  1.903553  22.048364  1.737619  161.077236   \n",
      "35063 2014-12-31 23:00:00  2.220812  21.337127  1.737619  161.585366   \n",
      "35064 2015-01-01 00:00:00  2.538071  19.914651  1.737619  178.861789   \n",
      "\n",
      "          MT_005      MT_006     MT_007      MT_008     MT_009  ...  \\\n",
      "0       0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "1       0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "2       0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "3       0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "4       0.000000    0.000000   0.000000    0.000000   0.000000  ...   \n",
      "...          ...         ...        ...         ...        ...  ...   \n",
      "35060  92.073171  340.773810  11.305822  315.656566  91.783217  ...   \n",
      "35061  86.280488  319.940476  11.588468  269.360269  76.486014  ...   \n",
      "35062  86.890244  314.732143  11.305822  251.683502  71.678322  ...   \n",
      "35063  83.841463  308.035714  10.740531  250.841751  64.685315  ...   \n",
      "35064  84.146341  279.761905  10.175240  249.158249  62.937063  ...   \n",
      "\n",
      "           MT_361   MT_362       MT_363       MT_364     MT_365    MT_366  \\\n",
      "0        0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "1        0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "2        0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "3        0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "4        0.000000      0.0     0.000000     0.000000   0.000000  0.000000   \n",
      "...           ...      ...          ...          ...        ...       ...   \n",
      "35060  333.511777  39700.0  1702.531646  2238.636364  74.967405  4.388531   \n",
      "35061  327.266238  38575.0  1649.789030  1477.272727  74.967405  3.949678   \n",
      "35062  306.209850  35475.0  1636.075949  1375.000000  64.211213  7.753072   \n",
      "35063  271.948608  28075.0  1546.413502  1232.954545  28.357236  7.314219   \n",
      "35064  188.436831  27800.0  1409.282700   954.545455  27.379400  4.095963   \n",
      "\n",
      "           MT_367      MT_368      MT_369       MT_370  \n",
      "0        0.000000    0.000000    0.000000     0.000000  \n",
      "1        0.000000    0.000000    0.000000     0.000000  \n",
      "2        0.000000    0.000000    0.000000     0.000000  \n",
      "3        0.000000    0.000000    0.000000     0.000000  \n",
      "4        0.000000    0.000000    0.000000     0.000000  \n",
      "...           ...         ...         ...          ...  \n",
      "35060  375.768218  108.931553  688.416422  8405.405405  \n",
      "35061  465.539947  154.841402  662.023460  8283.783784  \n",
      "35062  655.179982  195.325543  679.252199  7594.594595  \n",
      "35063  676.031607  161.519199  659.274194  6932.432432  \n",
      "35064  628.621598  131.886477  673.020528  7135.135135  \n",
      "\n",
      "[35065 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_ID = 1\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, el_resample)\n",
    "else:\n",
    "    from datetime import datetime\n",
    "    print(df[df['timestamp'].apply(lambda x: datetime.strptime('2014-12-31 23:00:00', '%Y-%m-%d %H:%M:%S') <= x < datetime.strptime('2015-1-1 00:00:00', '%Y-%m-%d %H:%M:%S'))].mean())\n",
    "    df_t = el_resample(df)\n",
    "    print(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 2. Consumption peaks (1 point)\n",
    "\n",
    "For each household, calculate, which month in 2014 had the highest consumption. Your function must output series, indexed by household ID (e.g., `MT_XXX`), and containing month as an integer (`1-12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.274476Z",
     "start_time": "2019-10-30T22:26:08.268426Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def cons_peak(df):\n",
    "    df = df[np.logical_and(df['timestamp'] >= '2014', df['timestamp'] < '2015')]\n",
    "    df = df.groupby(pd.Grouper(key='timestamp', freq='1M')).max().reset_index()\n",
    "    df = df.drop('timestamp', axis=1)\n",
    "    df.index += 1\n",
    "    df = df.idxmax()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.554208Z",
     "start_time": "2019-10-30T22:26:08.542546Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT_001     9\n",
      "MT_002     7\n",
      "MT_003     1\n",
      "MT_004     1\n",
      "MT_005     2\n",
      "          ..\n",
      "MT_366    10\n",
      "MT_367    10\n",
      "MT_368     6\n",
      "MT_369    10\n",
      "MT_370     9\n",
      "Length: 370, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_ID = 2\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, cons_peak)\n",
    "else:\n",
    "    s = cons_peak(df)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 3. Find minimum (2 points)\n",
    "\n",
    "Consider the following scalar function:\n",
    "\n",
    "$$\n",
    "f(x) = ax^2 + bx + c\n",
    "$$\n",
    "\n",
    "Given $a,b,c$, find $x$, which minimizes $f(x)$, and minimum value of $f(x)$. Note this:\n",
    "\n",
    "- $a,b,c$ are fixed, and generated in such a way, that minimum always exists ($f(x)$ is convex),\n",
    "- $x$ is a scalar value, i.e. 0-dimensional tensor.\n",
    "\n",
    "For reference, see `generate_coef` function, which is used to generate coefficients. Note, that since optimization process is not completely deterministic, the output is considered correct, if it falls within `1e-3` of actual values.\n",
    "\n",
    "This problem must be solved as an optimization one using gradient descent.\n",
    "\n",
    "For that, use only PyTorch functionality, `SciPy` (or alike) optimization routines are not allowed, neither is direct calculation using coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coeffs():\n",
    "    a = torch.rand(size=()) * 10\n",
    "    b = -10 + torch.rand(size=()) * 10\n",
    "    c = -10 + torch.rand(size=()) * 10\n",
    "    return a, b, c\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return x.pow(2) * a + x * b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(a, b, c):\n",
    "    opt = 'SGD'\n",
    "    max_iter = 10**6\n",
    "\n",
    "    if opt == 'SGD':\n",
    "        x = torch.randn(1, requires_grad=True)\n",
    "        optimizer = torch.optim.SGD([x], lr=1e-3)\n",
    "        \n",
    "        for iter in range(max_iter):\n",
    "            optimizer.zero_grad()\n",
    "            y = func(x,a,b,c)\n",
    "            y.backward()\n",
    "            optimizer.step()\n",
    "            if x.grad.abs() < 1e-3:\n",
    "                return x, y           \n",
    "    else:\n",
    "        lr = torch.tensor([1e-1], device=\"cpu\", dtype=torch.float, requires_grad=True)\n",
    "        x = torch.tensor([0], device=\"cpu\", dtype=torch.float, requires_grad=True) \n",
    "        for iter in range(max_iter):\n",
    "            if (x.grad is not None):\n",
    "                x.grad.data.zero_()\n",
    "            y = func(x,a,b,c)\n",
    "\n",
    "            y.backward()\n",
    "\n",
    "            if x.grad.abs() < 1e-3:\n",
    "                return x, y\n",
    "\n",
    "            x = torch.tensor([x - lr * x.grad], device=\"cpu\", dtype=torch.float, requires_grad=True)\n",
    "\n",
    "        print('min not found in wanted range.')\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.170219Z",
     "start_time": "2019-10-30T22:26:09.158251Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True])\n",
      "tensor([True])\n",
      "tensor([0.1332], requires_grad=True) tensor([-0.2561], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_ID = 3\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, find_min)\n",
    "else:\n",
    "    a, b, c = generate_coeffs()\n",
    "    x_min, val_min = find_min(a,b,c)\n",
    "    true_x_min = -b/(2*a)\n",
    "    true_y_min = func(true_x_min, a, b, c)\n",
    "    print(true_x_min - 1e-3 < x_min < true_x_min + 1e-3)\n",
    "    print(true_y_min - 1e-3 < val_min < true_y_min + 1e-3)\n",
    "    print(x_min, val_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 4. PyTorch `Dataset` (3 points)\n",
    "\n",
    "Implement a `torch.utils.data.Dataset` sub-class for the electricity consumption data. Individual training instances must be week-long univarite series of hourly consumption (input, 168 values), followed by 24-hours long series of hourly consumption (output, 24 values) for a single household. Such a class can be used when training a consumption forecast model, which uses 7 days of historical consumption to forecast next 24 hours of consumption.\n",
    "\n",
    "`__getitem__(self, idx)` must return a tuple of 1D tensors, `in_data` and `out_data`. `in_data` contains 168 hours of consumption (hourly), starting from some `start_ts`, while `out_data` must contain 24 hourly consumption values starting from `start_ts + 168 hours` for some household. `start_ts` should be sampled randomly.\n",
    "\n",
    "Also, you need to implement a `get_mapping(self, idx)` method, which allows to calculate `(household, starting time) -> idx` correspondence.\n",
    "\n",
    "This class will be validated as the following:\n",
    "\n",
    "- dataset object is created with some random `samples`: `dataset = ElDataset(df, samples)` ,\n",
    "- validator fetches random `idx` (between `0` and `len(dataset)`) from the dataset:\n",
    "```python\n",
    "household, start_ts = dataset.get_mapping(idx)\n",
    "hist_data, future_data = dataset[idx]\n",
    "```\n",
    "- then, `hist_data` and `future_data` are compared with the data, obtained directly from `df` using `household, start_ts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "24\n"
     ]
    }
   ],
   "source": [
    " if not TEST:\n",
    "    samples = 10\n",
    "    raw_data = df\n",
    "    sampled_data = df.iloc[list(torch.rand(samples) * len(raw_data))]\n",
    "    hourly_sampled_data = el_resample(raw_data)\n",
    "    households = list(hourly_sampled_data.columns)\n",
    "    households.remove('timestamp')\n",
    "    idx_mapping = {\n",
    "        i: {\n",
    "            'household': households[int(torch.rand(1) * len(households))],\n",
    "            'start_st_hist': date,\n",
    "            'end_st_hist': date + pd.DateOffset(days=7),\n",
    "            'end_st_future': date + pd.DateOffset(days=8)\n",
    "        } for i, date in enumerate(list(hourly_sampled_data['timestamp']))\n",
    "    }\n",
    "    idx_mapping\n",
    "    print(len(hourly_sampled_data[np.logical_and(\n",
    "        hourly_sampled_data['timestamp'] >= str(idx_mapping[0]['start_st_hist']),\n",
    "        hourly_sampled_data['timestamp'] < str(idx_mapping[0]['end_st_hist'])\n",
    "    )]))\n",
    "    print(len(hourly_sampled_data[np.logical_and(\n",
    "        hourly_sampled_data['timestamp'] >= str(idx_mapping[0]['end_st_hist']),\n",
    "        hourly_sampled_data['timestamp'] < str(idx_mapping[0]['end_st_future'])\n",
    "    )]))\n",
    "\n",
    "    hourly_sampled_data[np.logical_and(\n",
    "            hourly_sampled_data['timestamp'] >= str(idx_mapping[0]['start_st_hist']),\n",
    "            hourly_sampled_data['timestamp'] < str(idx_mapping[0]['end_st_hist'])\n",
    "        )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.531869Z",
     "start_time": "2019-10-30T22:26:09.523705Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "class ElDataset(Dataset):\n",
    "    \"\"\"Electricity dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, samples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: original electricity data (see HW intro for details).\n",
    "            samples (int): number of sample to take per household.\n",
    "        \"\"\"\n",
    "        self.samples = samples\n",
    "        self.raw_data = df\n",
    "        self.sampled_data = df.iloc[list(torch.rand(self.samples) * len(self.raw_data))]\n",
    "        self.hourly_sampled_data = self.raw_data.groupby(pd.Grouper(key='timestamp', freq='1H')).max().reset_index()\n",
    "        self.households = list(self.hourly_sampled_data.columns)\n",
    "        self.households.remove('timestamp')\n",
    "        self.idx_mapping = {\n",
    "            i: {\n",
    "                'household': self.households[int(torch.rand(1) * len(self.households))],\n",
    "                'start_st_hist': date,\n",
    "                'end_st_hist': date + pd.DateOffset(days=7),\n",
    "                'end_st_future': date + pd.DateOffset(days=8)\n",
    "            } for i, date in enumerate(list(self.hourly_sampled_data['timestamp']))\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.samples * (self.raw_data.shape[1] - 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query_obj = self.idx_mapping[idx]\n",
    "        household = query_obj['household']\n",
    "        timestamp = self.hourly_sampled_data['timestamp']\n",
    "        \n",
    "        hist_data = self.hourly_sampled_data[\n",
    "            np.logical_and(\n",
    "                timestamp >= str(query_obj['start_st_hist']),\n",
    "                timestamp < str(query_obj['end_st_hist'])\n",
    "            )\n",
    "        ]\n",
    "        future_data = self.hourly_sampled_data[\n",
    "            np.logical_and(\n",
    "                timestamp >= str(query_obj['end_st_hist']),\n",
    "                timestamp < str(query_obj['end_st_future'])\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        hist_data = torch.tensor(hist_data[household].tolist())\n",
    "        future_data = torch.tensor(future_data[household].tolist())\n",
    "\n",
    "        return hist_data, future_data\n",
    "\n",
    "    def get_mapping(self, idx):\n",
    "        mp = self.idx_mapping[idx]\n",
    "        household = mp['household']\n",
    "        start_ts = mp['start_st_hist']\n",
    "        return household, start_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.716713Z",
     "start_time": "2019-10-30T22:26:09.707934Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT_311 | 2011-01-05 04:00:00\n",
      "tensor([ 73.2820, 117.5842, 152.5986, 169.9711, 176.7276, 173.8402, 178.6622,\n",
      "        191.2127, 187.3532, 181.5592, 189.2782, 197.0067, 185.4187, 190.2502,\n",
      "        195.0722, 197.9692, 182.5217, 171.9057, 169.0087, 141.0106, 108.9220,\n",
      "         80.0192,  79.0568,  78.0943,  77.1319, 108.9220, 149.7016, 169.0087,\n",
      "        159.3551, 161.2897, 163.2146, 167.0741, 173.8402, 167.0741, 170.9432,\n",
      "        186.3811, 175.7652, 177.6997, 187.3532, 181.5592, 163.2146, 159.3551,\n",
      "        162.2522, 136.1886, 108.9220,  80.0192,  79.0568,  70.3850,  68.4601,\n",
      "        106.0250, 159.3551, 175.7652, 181.5592, 191.2127, 175.7652, 178.6622,\n",
      "        185.4187, 183.4937, 186.3811, 181.5592, 199.9037, 197.9692, 196.0347,\n",
      "        189.2782, 182.5217, 170.9432, 167.0741, 155.4957, 111.8094, 102.1752,\n",
      "         79.0568,  74.2445,  71.3475, 102.1752, 144.8797, 186.3811, 186.3811,\n",
      "        197.9692, 203.7632, 197.9692, 195.0722, 193.1473, 211.4822, 182.5217,\n",
      "        184.4562, 187.3532, 208.5852, 186.3811, 187.3532, 173.8402, 155.4957,\n",
      "        143.9076, 109.8845,  96.4004,  70.3850,  67.4976,  68.4601, 108.9220,\n",
      "        159.3551, 177.6997, 179.6246, 180.5967, 184.4562, 217.2762, 198.9317,\n",
      "        188.3157, 177.6997, 187.3532, 198.9317, 189.2782, 202.8008, 191.2127,\n",
      "        172.8681, 158.3927, 156.4581, 106.0250,  97.3628,  67.4976,  63.6477,\n",
      "         62.6853,  62.6853, 106.0250, 158.3927, 166.1116, 173.8402, 171.9057,\n",
      "        177.6997, 176.7276, 183.4937, 186.3811, 183.4937, 170.9432, 183.4937,\n",
      "        186.3811, 192.1752, 185.4187, 185.4187, 169.0087, 160.3176, 126.5351,\n",
      "        103.1376,  74.2445,  68.4601,  66.5351,  66.5351, 110.8470, 145.8422,\n",
      "        177.6997, 179.6246, 178.6622, 169.9711, 169.9711, 185.4187, 187.3532,\n",
      "        182.5217, 165.1492, 172.8681, 182.5217, 194.1097, 180.5967, 174.8027,\n",
      "        164.1867, 154.5332, 127.4976, 110.8470,  80.0192,  80.0192,  74.2445])\n",
      "tensor([ 68.4601, 109.8845, 151.6362, 181.5592, 171.9057, 184.4562, 173.8402,\n",
      "        178.6622, 179.6246, 175.7652, 196.0347, 204.7257, 174.8027, 181.5592,\n",
      "        192.1752, 195.0722, 184.4562, 176.7276, 169.9711, 136.1886, 123.6381,\n",
      "        104.1001,  85.8037,  80.9817])\n",
      "168\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "PROBLEM_ID = 4\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, ElDataset)\n",
    "else:\n",
    "    dataset = ElDataset(df, 1400)\n",
    "    household, start_st = dataset.get_mapping(100)\n",
    "    print(household, '|', start_st)\n",
    "    hist_data, future_data = dataset[100]\n",
    "    print(hist_data)\n",
    "    print(future_data)\n",
    "    print(len(hist_data))\n",
    "    print(len(future_data))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:26.661611Z",
     "start_time": "2019-10-30T22:39:26.654545Z"
    }
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    print(f\"{STUDENT}: {total_grade}\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
